{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26435,"status":"ok","timestamp":1706822800682,"user":{"displayName":"Yolanda","userId":"12899648984181845775"},"user_tz":0},"id":"aO5aWmnJQgho","outputId":"0c0d840d-bc3e-40cb-fb34-459e03810dc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import glob\n","import json\n","import csv\n","from PIL import Image\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, Subset\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torchvision.models import resnet18, resnet152\n","from torchsummary import summary\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bHYkKoCNRiK6"},"outputs":[],"source":["cd /content/drive/MyDrive/Yolanda_Task2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9p5uRNlRjib"},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\"\n","    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n","    torch.backends.cudnn.enabled   = True\n","\n","    return True\n","\n","device = 'cpu'\n","if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n","    print(\"Cuda installed! Running on GPU!\")\n","    device = 'cuda'\n","else:\n","    print(\"No GPU available!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzrjtW4oRuNv"},"outputs":[],"source":["data_dir = '/content/drive/MyDrive/Selected_Storms_curated'\n","csvpath = '/content/drive/MyDrive/storm_df.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syr1Nb9oRu3Z"},"outputs":[],"source":["# do not use timeseries data\n","from dataloader_norm import StormDatasetN\n","test_size = 0.3\n","trainset = StormDatasetN(data_dir,csvpath, train=True,storm='full', test_size=test_size)\n","testset = StormDatasetN(data_dir,csvpath, train=False,storm='full', test_size=test_size)\n","print(len(trainset))\n","print(len(testset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6y_uO6bJRwfD"},"outputs":[],"source":["# use timeseries data\n","from dataloader_norm import WindowStormDatasetN\n","test_size = 0.1\n","trainset = WindowStormDatasetN(data_dir,csvpath, train=True,storm='full', test_size=test_size)\n","testset = WindowStormDatasetN(data_dir,csvpath, train=False,storm='full', test_size=test_size)\n","print(len(trainset))\n","print(len(testset))"]},{"cell_type":"markdown","metadata":{"id":"u3Zez9ZHR8pZ"},"source":["## Architechture##\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VnSto41jR-ro"},"source":["### Simple CNN with 3 convolution layers##\n","\n","We first used the simplest cnn model to test the structure (only used images to predict the wind speed)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n86zWF7ESG0i"},"outputs":[],"source":["class SimpleCNN(nn.Module):\n","    def __init__(self, outdim):\n","        super(SimpleCNN, self).__init__()\n","\n","        inputsize = 366\n","\n","        # Define the convolutional layers\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout2d(p=0.2),\n","\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout2d(p=0.2),\n","\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout2d(p=0.2),\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(256 * (inputsize // 8) * (inputsize // 8), outdim),\n","            nn.ReLU(),\n","            )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"fwS7eI3AZM4S"},"source":["### CNN model in reference\n","\n","We used the CNN model we found online and tried to imporve the results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etEXpWHkZL9s"},"outputs":[],"source":["class CNNRe(nn.Module):\n","    def __init__(self):\n","        super(CNNRe, self).__init__()\n","        self.model_ft = models.resnet18(pretrained=True)\n","        num_ftrs = self.model_ft.fc.in_features\n","        # Define the first fully connected layer.\n","        self.fc1 = nn.Sequential(nn.Linear(num_ftrs, 64), nn.ReLU())\n","        # Define the second fully connected layer followed\n","        #by a ReLU activation and the final linear layer for regression.\n","        self.fc2 = nn.Sequential(nn.Linear(64, 64), nn.ReLU(), nn.Linear(64, 1))\n","        self.dp = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        x = self.model_ft.conv1(x)\n","        x = self.model_ft.bn1(x)\n","        x = self.model_ft.relu(x)\n","        x = self.model_ft.maxpool(x)\n","\n","        x = self.model_ft.layer1(x)\n","        x = self.model_ft.layer2(x)\n","        x = self.model_ft.layer3(x)\n","        x = self.model_ft.layer4(x)\n","\n","        x = self.model_ft.avgpool(x).squeeze(-1).squeeze(-1)\n","        x = self.dp(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"UkgG7tVESKbd"},"source":["### Resnet\n","\n","Tried to train different resnet as well\n","(such as resnet18, resnet50, resnet152)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uryHtES0SMN0"},"outputs":[],"source":["class Resnet(nn.Module):\n","    def __init__(self, outdim):\n","        super(Resnet, self).__init__()\n","        self.resnet18 = resnet18(pretrained=True)\n","        self.resnet18.fc = nn.Sequential(\n","            nn.Linear(self.resnet18.fc.in_features, outdim),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.resnet18(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyOlinRDk1nD"},"outputs":[],"source":["class CNN_resnet(nn.Module):\n","    '''\n","    This model used a trained ResNet152.\n","    '''\n","    def __init__(self):\n","        super(CNN_resnet, self).__init__()\n","        self.cnn = resnet152(pretrained=True)  # out_features=1000\n","        self.fc = nn.Sequential(\n","            nn.Linear(1000, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 64),\n","            nn.ReLU(),\n","            nn.Linear(64,1),\n","        )\n","\n","    def forward(self, x, x_ft):\n","        x = self.cnn(x)\n","        x = self.fc(x)\n","        return x.squeeze()"]},{"cell_type":"markdown","metadata":{"id":"fW9rQeBVSRjL"},"source":["### CNN+LSTM model##\n","\n","During this process, we also tried to use CNN+LSTM model to train and predict wind speed for all features.\n","\n","We tried to modify the CNN model to find the most appropriate architecture(utilizing the CNN models described above).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_OH4_c0BSTA7"},"outputs":[],"source":["class CNNLSTM(nn.Module):\n","    def __init__(self, indim=256, timedim=3):\n","        super(CNNLSTM, self).__init__()\n","        # # resnet\n","        # self.cnn = Resnet(indim)\n","        # indim += timedim\n","        # self.lstm = nn.LSTM(input_size=indim, hidden_size=256, num_layers=3, batch_first=True)\n","\n","        # simpleCNN\n","        self.cnn = SimpleCNN(indim)\n","        indim += timedim\n","        self.lstm = nn.LSTM(input_size=indim, hidden_size=256, num_layers=3, batch_first=True)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64,1),\n","        )\n","\n","    def forward(self, x, x_ft):\n","        xsh = x.shape\n","        if len(xsh)==5:  # (bs, seq_len, C, H, W)\n","            x = x.reshape(-1, *xsh[2:])\n","            x = self.cnn(x)\n","            x = x.reshape(xsh[0], xsh[1], -1)\n","            x = torch.cat((x, x_ft), dim=-1)  # add features\n","            out, hidden = self.lstm(x)\n","            x = self.fc(out[:, -1, :])\n","            return x.squeeze()\n","        else:\n","            x = self.cnn(x)\n","            x = torch.cat((x, x_ft), dim=1)  # add features\n","            out, hidden = self.lstm(x.unsqueeze(0))\n","            x = self.fc(out[:, -1, :])\n","            return x.squeeze()"]},{"cell_type":"markdown","metadata":{"id":"6sSG9FzhXE_W"},"source":["### Problem with LSTM model\n","![loss](figs/resnet-lstm-loss.png)\n","\n","![predict plot](figs/resnet-lstm-res.png)\n","\n","It is obviously to see what the problem is: we got all the same predictions when using this model.\n","\n","We attempted the following approaches; however, it is evident that the issue is unresolved. Clearly, the issue did not lie here:\n","\n","* change activate function (relu/leaky-relu)\n","* reduce learning rate (0.05/0.01/0.001/0.0001)\n","* add dropout and batchnorm\n","* use or not use relative_time and other features\n","* change normalize (normalize images to [0,1] or [-1,1], norm or not norm relative_time)\n","* change model architecture from resnet18 to a more simple one (3-layer convolution) or a more complex one (resnet50)\n","* add more linear layer after LSTM"]},{"cell_type":"markdown","metadata":{"id":"ooOOctsdh4EO"},"source":["## Here is results using above models.\n","\n","It can be seen that while some of the RMSE values produce promising results, the R-squared values are not satisfactory. Moreover, these results were obtained without solving the previously mentioned LSTM problem."]},{"cell_type":"markdown","metadata":{"id":"3YuPfX1RVmdd"},"source":["\n","| model | rmse | r2 |\n","| ------- | ------- | ------- |\n","| SimpleCNN + LSTM | 22.028 | -0.137 |\n","| resnet18 + LSTM | 20.724 | -0.006 |\n","| resnet50 + LSTM | 5.920 | -0.919 |\n","| SimpleCNN | 7.749 | -2.276 |\n","| resnet152 | 11.670 | 0.763 |\n","| CNN in ref| 62.1424|       |\n","\n","in which the best model is resnet152:\n","\n","![loss](figs/resnet-loss.png)\n","\n","![predict plot](figs/resnet-res.png)"]},{"cell_type":"markdown","metadata":{"id":"gQ1JcQoQSy_A"},"source":["## training loop\n","\n","Here are the train and evaluate models we used to produce the loss images and predict results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pagOp_HtS0k2"},"outputs":[],"source":["def train(model, optimizer, criterion, data_loader):\n","    '''\n","    Function to train the model.\n","    '''\n","    model.train()\n","    train_loss, train_rmse = 0, 0\n","    pbar = tqdm(data_loader)\n","    for data in pbar:\n","        X = data['image'].to(device)\n","        time = data['relative_time'].to(device)\n","        time_diff = data['time_diff'].to(device)\n","        ocean = data['ocean'].to(device)\n","        x_ft = torch.cat([time.unsqueeze(dim=-1),time_diff.unsqueeze(dim=-1), ocean.unsqueeze(dim=-1)], dim = -1).float()\n","        y = data['wind_speed'].float().to(device)\n","\n","        optimizer.zero_grad()\n","        y_pred = model(X, x_ft)\n","        loss = criterion(y_pred, y)\n","        loss.backward()\n","        train_loss += loss*X.size(0)\n","        train_rmse += torch.sqrt(loss)*X.size(0)\n","        optimizer.step()\n","        pbar.set_description(f\"loss: {loss:.4f}\")\n","\n","    train_loss = train_loss/len(data_loader.dataset)\n","    train_rmse = train_rmse/len(data_loader.dataset)\n","    return train_loss, train_rmse # Return the average loss and RMSE\n","\n","def evaluate(model, data_loader):\n","    '''\n","    Function to evaluate the model\n","    '''\n","    model.eval()\n","    y_true, y_pred = [], []\n","    for data in data_loader:\n","        with torch.no_grad():\n","            X = data['image'].to(device)\n","            time = data['relative_time'].to(device)\n","            time_diff = data['time_diff'].to(device)\n","            ocean = data['ocean'].to(device)\n","            x_ft = torch.cat([time.unsqueeze(dim=-1),time_diff.unsqueeze(dim=-1), ocean.unsqueeze(dim=-1)], dim = -1).float()\n","            y = data['wind_speed'].to(device)\n","            # predict the wind speeds\n","            y_p = model(X, x_ft)\n","            y_true.append(y.cpu().numpy())\n","            y_pred.append(y_p.cpu().numpy())\n","    # Concat true and predicted wind speeds.\n","    y_pred = np.concatenate(y_pred, 0)\n","    y_pred = np.round(y_pred)\n","    y_true = np.concatenate(y_true, 0)\n","    # Calculate MSE, RMSE and R-squared.\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_true, y_pred)\n","    print('rmse: ', rmse)\n","    print('r2: ', r2)\n","    return y_true, y_pred # Return true and predicted wind speeds."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZMYULItS8Ey"},"outputs":[],"source":["def train_model(model,trainset, n_epoch=20, batchsize=16, lr=0.001, weight_decay=1e-6):\n","    set_seed(42)\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[i*10 for i in range(n_epoch//10)], gamma=0.5)\n","\n","    # load data for training data\n","    trainloader = DataLoader(trainset, batchsize, shuffle=True, num_workers=4)\n","\n","    # model save path\n","    savepath = os.path.join('checkpoints','cnn')\n","    if os.path.exists(savepath)==False:\n","        os.mkdir(savepath)\n","\n","    start_epoch = 1\n","    modellist = sorted(os.listdir(savepath))\n","    if len(modellist)>0:\n","        checkpoint = modellist[-1]\n","        model.load_state_dict(torch.load(os.path.join(savepath, checkpoint)))\n","        start_epoch += int(checkpoint.split('.')[0])\n","\n","    # train the model\n","    loss = []\n","    rmse = []\n","\n","    for epoch in range(start_epoch, n_epoch+start_epoch):\n","        train_loss, train_rmse = train(model, optimizer, criterion, trainloader)\n","        loss.append(train_loss.item())\n","        rmse.append(train_rmse.item())\n","        if scheduler:\n","            scheduler.step()\n","\n","        # pbar.set_description(f\"loss: {train_loss.item():.4f}, mse: {train_mse.item():.4f}\")\n","\n","        # save checkpoints\n","        if (np.mod(epoch, 5) == 0):\n","            torch.save(model.state_dict(), os.path.join(savepath, \"{:03d}.pth\".format(epoch)))\n","\n","    # plot loss and accuracy on trainset\n","    fig, ax = plt.subplots(1,2, figsize=(8,4))\n","    ax[0].plot(list(range(n_epoch)), loss, label='loss')\n","    ax[1].plot(list(range(n_epoch)), rmse, c='orange', label='mse')\n","    ax[0].set_xlabel('epoch')\n","    ax[0].set_title('loss')\n","    ax[1].set_xlabel('epoch')\n","    ax[1].set_title('rmse')\n","    plt.show()\n","\n","def evaluate_model(model, testset, batchsize=64):\n","    testloader = DataLoader(testset, batchsize, shuffle=False, num_workers=4)\n","    y_true, y_pred = evaluate(model, testloader)\n","    print(y_pred)\n","    x = np.arange(len(y_true))\n","    df = pd.DataFrame({'true': y_true, 'pred': y_pred})\n","    # df = df.sort_values(by='true')\n","    plt.plot(x, df['true'], color='blue', label='true')\n","    plt.plot(x, df['pred'], color='red', label='predict')\n","    plt.legend(loc='best')\n","    plt.show()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAMhq6E3GAjEUUxy9JRmig","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
